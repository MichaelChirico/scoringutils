% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/score.R
\name{score}
\alias{score}
\title{Evaluate forecasts}
\usage{
score(data, metrics = NULL, ...)
}
\arguments{
\item{data}{A data.frame or data.table with the following columns:
\itemize{
\item \code{observed} - the observed values
\item \code{predicted} - predictions, predictive samples or predictive quantiles
\item \code{model} - name of the model or forecaster who made a prediction
}

Depending on the forecast type, one of the following columns may be required:
\itemize{
\item \code{sample_id} - index for the predictive samples in the 'predicted' column
\item \code{quantile}: quantile-level of the corresponding value in \code{predicted}
}

For more information see the vignettes and the example data
(\link{example_quantile}, \link{example_continuous},
\link{example_integer}, \code{\link[=example_point]{example_point()}}, and \link{example_binary}).}

\item{metrics}{the metrics you want to have in the output. If \code{NULL} (the
default), all available metrics will be computed. For a list of available
metrics see \code{\link[=available_metrics]{available_metrics()}}, or  check the \link{metrics} data set.}

\item{...}{additional parameters passed down to other functions.}
}
\value{
A data.table with unsummarised scores. There will be one score per
quantile or sample_id, which is usually not desired, so you should almost
always run \code{\link[=summarise_scores]{summarise_scores()}} on the unsummarised scores.
}
\description{
This function allows automatic scoring of forecasts using a
range of metrics. For most users it will be the workhorse for
scoring forecasts as it wraps the lower level functions package functions.
However, these functions are also available if you wish to make use of them
independently.

A range of forecasts formats are supported, including quantile-based,
sample-based, binary forecasts. Prior to scoring, users may wish to make use
of \code{\link[=validate]{validate()}} to ensure that the input data is in a supported
format though this will also be run internally by \code{\link[=score]{score()}}. Examples for
each format are also provided (see the documentation for \code{data} below or in
\code{\link[=validate]{validate()}}).

Each format has a set of required columns (see below). Additional columns may
be present to indicate a grouping of forecasts. For example, we could have
forecasts made by different models in various locations at different time
points, each for several weeks into the future. It is important, that there
are only columns present which are relevant in order to group forecasts.
A combination of different columns should uniquely define the
\emph{unit of a single forecast}, meaning that a single forecast is defined by the
values in the other columns. Adding additional unrelated columns may alter
results.

To obtain a quick overview of the currently supported evaluation metrics,
have a look at the \link{metrics} data included in the package. The column
\code{metrics$Name} gives an overview of all available metric names that can be
computed. If interested in an unsupported metric please open a \href{https://github.com/epiforecasts/scoringutils/issues}{feature request} or consider
contributing a pull request.

For additional help and examples, check out the \href{https://epiforecasts.io/scoringutils/articles/scoringutils.html}{Getting Started Vignette}
as well as the paper \href{https://arxiv.org/abs/2205.07090}{Evaluating Forecasts with scoringutils in R}.
}
\examples{
library(magrittr) # pipe operator
data.table::setDTthreads(1) # only needed to avoid issues on CRAN

validate(example_quantile)
score(example_quantile) \%>\%
  add_coverage(by = c("model", "target_type")) \%>\%
  summarise_scores(by = c("model", "target_type"))

# set forecast unit manually (to avoid issues with scoringutils trying to
# determine the forecast unit automatically), check forecasts before scoring
example_quantile \%>\%
  set_forecast_unit(
    c("location", "target_end_date", "target_type", "horizon", "model")
  ) \%>\%
  validate() \%>\%
  score()

# forecast formats with different metrics
\dontrun{
score(example_binary)
score(example_quantile)
score(example_integer)
score(example_continuous)
}

# score point forecasts (marked by 'NA' in the quantile column)
score(example_point) \%>\%
  summarise_scores(by = "model", na.rm = TRUE)

}
\references{
Funk S, Camacho A, Kucharski AJ, Lowe R, Eggo RM, Edmunds WJ
(2019) Assessing the performance of real-time epidemic forecasts: A
case study of Ebola in the Western Area region of Sierra Leone, 2014-15.
PLoS Comput Biol 15(2): e1006785. \doi{10.1371/journal.pcbi.1006785}
}
\author{
Nikos Bosse \email{nikosbosse@gmail.com}
}
