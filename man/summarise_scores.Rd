% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/summarise_scores.R
\name{summarise_scores}
\alias{summarise_scores}
\title{Summarise scores as produced by \code{\link[=score]{score()}}}
\usage{
summarise_scores(
  scores,
  by = NULL,
  FUN = mean,
  relative_skill = FALSE,
  metric = "auto",
  baseline = NULL,
  ...
)
}
\arguments{
\item{scores}{a data.table of unsummarised scores as produced by
\code{\link[=score]{score()}}}

\item{by}{character vector with column names to summarise scores by. Default
is \code{NULL}, meaning that the only summary that takes is place is summarising
over quantiles (in case of quantile-based forecasts),
such that there is one score per forecast as
defined by the unit of a single forecast
(rather than one score for every quantile).}

\item{FUN}{a function used for summarising scores. Default is \code{mean}.}

\item{relative_skill}{logical, whether or not to compute relative
performance between models based on pairwise comparisons.
If \code{TRUE} (default is \code{FALSE}), then a column called
'model' must be present in the input data. For more information on
the computation of relative skill, see \code{\link[=pairwise_comparison]{pairwise_comparison()}}.
Relative skill will be calculated for the aggregation level specified in
\code{by}.}

\item{metric}{character with the name of the metric for which
a relative skill shall be computed. If equal to 'auto' (the default), then
this will be either interval score, crps or brier score (depending on which
of these is available in the input data)}

\item{baseline}{character string with the name of a model. If a baseline is
given, then a scaled relative skill with respect to the baseline will be
returned. By default (\code{NULL}), relative skill will not be scaled with
respect to a baseline model.}

\item{...}{additional parameters passed down to lower-level functions.
For example, the following arguments can change how weighted interval
scores are computed:
\itemize{
\item \code{count_median_twice} that controls how the interval scores for different
intervals are summed up. This should be a logical (default is \code{FALSE}) that
indicates whether or not to count the median twice when summarising.
This would conceptually treat the
median as a 0\% prediction interval, where the median is the lower as well as
the upper bound. The alternative is to treat the median as a single quantile
forecast instead of an interval. The interval score would then
be better understood as an average of quantile scores.)
}}
}
\description{
Summarise scores as produced by \code{\link[=score]{score()}}-
}
\examples{
library(scoringutils)
library(magrittr) # pipe operator

# summarise over samples or quantiles to get one score per forecast
scores <- score(example_quantile)
summarise_scores(scores)

# get scores by model
summarise_scores(scores, by = c("model"))

# get scores by model and target type
summarise_scores(scores, by = c("model", "target_type"))

# get standard deviation
summarise_scores(scores, by = "model", FUN = sd)

# get quantiles of scores
# make sure to aggregate over ranges first
summarise_scores(scores,
  by = "model", FUN = quantile,
  probs = c(0.25, 0.5, 0.75)
)

# get ranges
# summarise_scores(scores, by = "range")
}
\keyword{scoring}
