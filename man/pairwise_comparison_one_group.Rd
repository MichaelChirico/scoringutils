% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pairwise-comparisons.R
\name{pairwise_comparison_one_group}
\alias{pairwise_comparison_one_group}
\title{Do Pairwise Comparison for one Set of Forecasts}
\usage{
pairwise_comparison_one_group(scores, metric, baseline, summarise_by, ...)
}
\arguments{
\item{scores}{A data.frame of unsummarised scores as produced by
\code{\link[=eval_forecasts]{eval_forecasts()}}}

\item{metric}{A character vector of length one with the metric to do the
comparison on. The default is "auto", meaning that either "interval_score",
"crps", or "brier_score" will be selected where available.
See \code{\link[=available_metrics]{available_metrics()}} for available metrics.}

\item{baseline}{character vector of length one that denotes the baseline
model against which to compare other models.}

\item{summarise_by}{character vector of columns to group the summary by. By
default, this is equal to \code{by} and no summary takes place. But sometimes you
may want to to summarise over categories different from the scoring.
\code{summarise_by} is also the grouping level used to compute (and possibly plot)
the probability integral transform(pit).}

\item{...}{additional arguments, such as test options that can get passed
down to lower level functions. The following options are available:
\code{oneSided} (Boolean, default is \code{FALSE}, whether two conduct a one-sided
instead of a two-sided test), \code{test_type} (character, either "non_parametric"
or "permutation" determining which kind of test shall be conducted to
determine p-values. Default is "non-parametric), \code{n_permutations} (number of
permutations for a permutation test. Default is 999). See
\code{\link[=compare_two_models]{compare_two_models()}} for more information.}
}
\description{
This function does the pairwise comparison for one set of forecasts, but
multiple models involved. It gets called from \code{\link[=pairwise_comparison]{pairwise_comparison()}}.
\code{\link[=pairwise_comparison]{pairwise_comparison()}} splits the data into arbitrary subgroups specified
by the user (e.g. if pairwise comparison should be done separately for
different forecast targets) and then the actual pairwise comparison for that
subgroup is managed from \code{\link[=pairwise_comparison_one_group]{pairwise_comparison_one_group()}}. In order to
actually do the comparison between two models over a subset of common
forecasts it calls \code{\link[=compare_two_models]{compare_two_models()}}.
}
