% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scoringutils.R
\docType{package}
\name{scoringutils}
\alias{scoringutils}
\title{scoringutils}
\description{
This package is designed to help with assessing the quality of predictions.
It provides a collection of proper scoring rules and metrics as well that
can be accessed independently or collectively through higher-level wrapper
functions.

Predicitions can be either probabilistic forecasts (generally predictive
samples generated by Markov Chain Monte Carlo procedures) or point forecasts.
The type of the predictions and the true values can be either continuous,
integer, or binary.

A collection of different metrics and scoring rules can be accessed through
the function \code{\link{eval_forecasts()}} with the correct prediction type
(probabilistic/point prediction, and continuous/integer/binary) specified.

The following functions can also be accessed directly:
}
\section{probabilistic - integer}{

\itemize{
\item \code{\link{PIT}}
\item \code{\link{bias}}
\item \code{\link{sharpness}}
\item \code{\link{crps}}
\item \code{\link{dss}}
}
}

\section{probabilistic - binary}{

\itemize{
\item \code{\link{Brier_score}}
}
}

\section{probabilistic - continuous}{

\itemize{
\item .
}
}

\section{point prediction - integer}{

\itemize{
\item .
}
}

\section{point prediction - binary}{

\itemize{
\item .
}
}

\section{point prediction - continuous}{

\itemize{
\item .
}
}

