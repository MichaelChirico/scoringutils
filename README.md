<!-- badges: start -->
 [![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental) [![Travis build status](https://travis-ci.org/epiforecasts/scoringutils.svg?branch=master)](https://travis-ci.org/epiforecasts/scoringutils) [![codecov](https://codecov.io/gh/epiforecasts/scoringutils/branch/master/graphs/badge.svg)](https://codecov.io/gh/epiforecasts/scoringutils/) 
<!-- badges: end -->

 

# scoringutils
Utilities and Functions for Scoring Forecasts


## Components

### Probabilistic Forecasts

  #### binary forecasts
    - Brier Score
  
  #### integer-valued forecasts
    - PIT / calibration
    - bias
    - sharpness
    - DSS
    - CRPS

  #### continuous forecasts

### Point Forecasts

  #### binary forecasts
    - 

  #### integer-valued forecasts
    - 

  #### continuous forecasts
    - 



### Todo



  
### Things to discuss
  - [ ] do we need an option for working with datetime values
  - [ ] decide on nomenclature of variables
  - [ ] Do we want a vignette, or is the manual enough? 
  - [ ] What other functionality do we want to include? Also: what is already there?
  - [ ] Should we / can we wrap functions from other packages? 
  - [ ] How thorough should formal testing be? 
  - [ ] Do we want to implement something for probabilistic non-MCMC predictions?
  - [ ] should we make a formal distinction between absolute and comparative metrics?
  - [ ] How do we want to organise error handling? in a separate function? at the lowest level only?




