#' @title scoringutils
#'
#' @description
#' This package is designed to help with assessing the quality of predictions.
#' It provides a collection of proper scoring rules and metrics as well that
#' can be accessed independently or collectively through a higher-level wrapper
#' function.
#'
#' Predictions can be either probabilistic forecasts (generally predictive
#' samples generated by Markov Chain Monte Carlo procedures), quantile
#' forecasts or point forecasts. The true values can be either continuous,
#' integer, or binary.
#'
#' A collection of different metrics and scoring rules can be accessed through
#' the function [eval_forecasts()]. Given a data.frame of the
#' correct form the function will automatically figure out the type of
#' prediction and true values and return appropriate scoring metrics.
#'
#' The package also has a lot of default visualisation based on the output
#' created by [eval_forecasts()].
#'
#' \itemize{
#' \item [score_table()]
#' \item [correlation_plot()]
#' \item [wis_components()]
#' \item [range_plot()]
#' \item [score_heatmap()]
#' \item [plot_predictions()]
#' \item [interval_coverage()]
#' \item [quantile_coverage()]
#' }
#'
#' Alternatively, the following functions can be accessed directly:
#'
#' \itemize{
#' \item [brier_score()]
#' \item [pit()]
#' \item [bias()]
#' \item [quantile_bias()]
#' \item [sharpness()]
#' \item [crps()]
#' \item [logs()]
#' \item [dss()]
#' \item [ae_median_sample()]
#' }
#'
#' Predictions can be evaluated in a lot of different formats. If you want to
#' convert from one format to the other, the following helper functions can
#' do that for you:
#'
#' \itemize{
#' \item [sample_to_range_long()]
#' \item [sample_to_quantile()]
#' \item [quantile_to_range_long()]
#' \item [range_long_to_quantile()]
#' }
#'
#' @docType package
#' @name scoringutils

NULL
