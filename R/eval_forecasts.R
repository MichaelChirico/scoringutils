#' @title Evaluate forecasts
#'
#' @description The function \code{eval_forecasts} is an easy to use wrapper
#' of the lower level functions in the \code{scoringutils} package.
#' It can be used to score probabilistic or quantile forecasts of
#' continuous, integer-valued or binary variables.
#'
#' @details the following metrics are used where appropriate:
#' \itemize{
#'   \item {Interval Score} for quantile forecasts. Smaller is better. See
#'   \code{\link{interval_score}} for more information.
#'   \item {Brier Score} for a probability forecast of a binary outcome.
#'   Smaller is better. See \code{\link{brier_score}} for more information.
#'   \item {Bias} 0 is good, 1 and -1 are bad.
#'   See \code{\link{bias}} for more information.
#'   \item {Sharpness} Smaller is better. See \code{\link{sharpness}} for more
#'   information.
#'   \item {Calibration} represented through the p-value of the
#'   Anderson-Darling test for the uniformity of the Probability Integral
#'   Transformation (PIT). For integer valued forecasts, this p-value also
#'   has a standard deviation. Larger is better.
#'   See \code{\link{pit}} for more information.
#'   \item {DSS} Dawid-Sebastiani-Score. Smaller is better.
#'   See \code{\link{dss}} for more information.
#'   \item {CRPS} Continuous Ranked Probability Score. Smaller is better.
#'   See \code{\link{crps}} for more information.
#'   \item {Log Score} Smaller is better. Only for continuous forecasts.
#'   See \code{\link{logs}} for more information.
#' }
#'
#' @param data A data.frame or data.table with the correct columns.
#' Note: it is easiest to have a look at the example files provided in the
#' package and in the examples below.
#' Regardless of the forecast type,the following columns need to be present:
#' \itemize{
#'   \item \code{true_values} the true observed values
#'   \item \code{id} A unique identifier of the true values. Could be a date
#'   or just a running index}
#' All forecasts except the quantile forecasts need a \code{predictions} column:
#' \itemize{
#' \item \code{predictions} predictions or predictive samples for one
#'   true value.}
#' For integer and continuous forecasts a \code{sample} column is needed:
#' \itemize{
#'   \item \code{sample} an index to identify the predictive samples in the
#'   predictiions column generated by one model for one true value. Only
#'   necessary for continuous and integer forecasts, not for
#'   binary predictions.}
#' For quantile forecasts the data can either be provided in a long or in a
#' wide format. The wide format needs columns with the quantile forecasts
#' \itemize{
#'   \item {quantile forecasts} a number of pairs of columns with
#'   quantile predictions for a certain range. For a 50% interval
#'   (corresponding to the 25% and
#'   75% quantile), one column has to be named \code{lower_50} and one
#'   \code{upper_50}.
#'   For the median, there has to a column \code{lower_0} and one
#'   \code{upper_0}
#'   }
#' The long format needs the following columns
#' \itemize{
#'   \item \code{predictions} the quantile forecasts
#'   \item \code{boundary} values should be either "lower" or "upper", depending
#'   on whether the prediction is for the lower or upper bound of a given range
#'   \item {range} the range for which a forecast was made. For a 50\% interval
#'   the range should be 50. The forecast for the 25\% quantile should have
#'   the value in the \code{predictions} column, the value of \code{range}
#'   should be 50 and the value of \code{boundary} should be "lower".
#'   If you want to score the median (i.e. \code{range = 0}), you still
#'   need to include a lower and an upper estimate, so the median has to
#'   appear twice.}
#' @param by character vector of columns to group scoring by. The default
#' is \code{c("model")}, but you could e.g. group over different locations
#' or horizons. Note that a column of the corresponding name must be
#' present in the data. If you don't want any grouping, set \code{by = NULL}
#' @param summarise_by character vector of columns to group the summary by. By
#' default, this is equal to `by`. But sometimes you may want to to summarise
#' over categories different from the scoring. If you e.g. want to have the
#' quantiles for plotting you may want to score by regions, but then summarise
#' over these regions to display the performance across regions.
#' @param summarised if \code{TRUE} (the default), only one average score is
#' returned per unit specified through `summarise_by`.
#' @param quantiles numeric vector of quantiles to be returned when summarising.
#' Instead of just returning a mean, quantiles will be returned for the
#' groups specified through `summarise_by`. By default, no quantiles are
#' returned.
#' @param sd if TRUE (the default is FALSE) the standard deviation of all
#' metrics will be returned when summarising.
#' @param pit_plots if TRUE (not the default), pit plots will be returned. For
#' details see \code{\link{pit}}.
#' @param pit_arguments pass down additional arguments to the \code{\link{pit}}
#' function.
#' @param interval_score_arguments pass down additional arguments to the
#' \code{\link{interval_score}} function, e.g. \code{weigh = TRUE}.
#'
#' @return A data.table with appropriate scores. For binary predictions,
#' the Brier Score will be returned, for quantile predictions the interval
#' score, as well as adapted metrics for calibration, sharpness and bias. The
#' calibration metric is the percentage of true values that fall into a given
#' range, the sharpness is determined as the average width of the 50\%
#' interval range and bias is estimated as the percentage of true values that
#' fall above the median, transformed to [-1, 1].
#' For integer forecasts, Sharpness, Bias, DSS, CRPS, LogS, and
#' pit_p_val (as an indicator of calibration) are returned. For integer
#' forecasts, pit_sd is returned (to account for the randomised PIT),
#' but no Log Score is returned (the internal estimation relies on a
#' kernel density estimate which is difficult for integer-valued forecasts).
#' If \code{summarised = TRUE} the average score per model is returned.
#' If specified, quantiles and standard deviation of scores can also be returned
#' when summarising.
#'
#' @importFrom data.table ':=' setDT %like%
#' @importFrom stats quantile
#'
#' @examples
#' ## Probability Forecast for Binary Target
#' binary_example <- data.table::setDT(scoringutils::binary_example_data)
#' eval <- scoringutils::eval_forecasts(binary_example, quantiles = c(0.7), sd = TRUE)
#' eval <- scoringutils::eval_forecasts(binary_example, summarised = FALSE)
#'
#' ## Quantile Forecasts
#' # wide format
#' quantile_example <- data.table::setDT(scoringutils::quantile_example_data_wide)
#' eval <- scoringutils::eval_forecasts(quantile_example,
#'                                      by = c("model", "horizon"),
#'                                      summarise_by = "model",
#'                                      quantiles = c(0.05, 0.95),
#'                                      sd = TRUE,
#'                                      interval_score_arguments = list(weigh = TRUE))
#' eval <- scoringutils::eval_forecasts(quantile_example, summarised = FALSE)
#'
#' #long format
#' eval <- scoringutils::eval_forecasts(scoringutils::quantile_example_data_long)
#'
#' ## Integer Forecasts
#' integer_example <- data.table::setDT(scoringutils::integer_example_data)
#' eval <- scoringutils::eval_forecasts(integer_example,
#'                                      by = c("model", "horizon"),
#'                                      quantiles = c(0.1, 0.9),
#'                                      sd = TRUE,
#'                                      pit_plots = TRUE,
#'                                      pit_arguments = list(n_replicates = 30,
#'                                                           plot = TRUE))
#' eval <- scoringutils::eval_forecasts(integer_example, summarised = FALSE)
#'
#' ## Continuous Forecasts
#' continuous_example <- data.table::setDT(scoringutils::continuous_example_data)
#' eval <- scoringutils::eval_forecasts(continuous_example, by = c("model", "horizon"))
#' eval <- scoringutils::eval_forecasts(continuous_example,
#'                                      quantiles = c(0.5, 0.9),
#'                                      sd = TRUE,
#'                                      by = c("model", "horizon"),
#'                                      summarised = TRUE)
#'
#' @author Nikos Bosse \email{nikosbosse@gmail.com}
#' @references Funk S, Camacho A, Kucharski AJ, Lowe R, Eggo RM, Edmunds WJ
#' (2019) Assessing the performance of real-time epidemic forecasts: A
#' case study of Ebola in the Western Area region of Sierra Leone, 2014-15.
#' PLoS Comput Biol 15(2): e1006785.
#' \url{https://doi.org/10.1371/journal.pcbi.1006785}
#' @export
#'


eval_forecasts <- function(data,
                           by = c("model"),
                           summarise_by = by,
                           summarised = TRUE,
                           quantiles = c(),
                           sd = FALSE,
                           pit_plots = FALSE,
                           pit_arguments = list(plot = FALSE),
                           interval_score_arguments = list()) {


  # preparations ---------------------------------------------------------------
  data.table::setDT(data)

  # helper function to add quantiles to summarised predictions
  add_quantiles <- function(dt, varnames, quantiles, by) {
    for (varname in varnames) {
      dt[, paste0(varname, "_", quantiles) := as.list(quantile(get(varname),
                                                               probs = quantiles,
                                                               na.rm = TRUE)),
         by = c(by)]
    }
    return(dt)
  }

  add_sd <- function(dt, varnames, by) {
    for (varname in varnames) {
      dt[, paste0(varname, "_sd") := sd(get(varname), na.rm = TRUE), by = by]
    }
    return(dt)
  }


  # check if predictions are integer, continuous, etc. -------------------------
  if (any(grepl("lower", names(data))) | "boundary" %in% names(data)) {
    prediction_type <- "quantile"
  } else if (all.equal(data$predictions, as.integer(data$predictions)) == TRUE) {
    prediction_type <- "integer"
  } else {
    prediction_type <- "continuous"
  }

  if (all.equal(data$true_values, as.integer(data$true_values)) == TRUE) {
    if (all(data$true_values %in% c(0,1))) {
      target_type = "binary"
    } else {
      target_type = "integer"
    }
  } else {
    target_type = "continuous"
  }


  # Score binary predictions ---------------------------------------------------
  if (target_type == "binary") {

    res <- data[, "brier_score" := scoringutils::brier_score(true_values, predictions),
         by = c("id", by)]

    if (summarised) {
      # add quantiles
      if (!is.null(quantiles)) {
        res <- add_quantiles(res, "brier_score", quantiles, by = summarise_by)
      }

      # add standard deviation
      if (sd) {
        res[, "brier_score_sd" := sd(brier_score, na.rm = TRUE), by = c(summarise_by)]
      }

      # summarise by taking the mean over all relevant columns
      res <- data[, lapply(.SD, mean, na.rm = TRUE),
                 .SDcols = colnames(res) %like% "brier",
                 by = summarise_by]

    }
    return(res)
  }

  # Score quantile predictions -------------------------------------------------
  if (prediction_type == "quantile") {

    # check if long or wide format
    if ("boundary" %in% names(data)) {
      wide = FALSE
    } else {
      wide = TRUE
    }

    if (wide) {
      # convert into long format
      colnames <- colnames(data)
      ranges <- colnames[grepl("lower", colnames) | grepl("upper", colnames)]

      data <- data.table::melt(data,
                               measure.vars = ranges,
                               variable.name = "range",
                               value.name = "predictions")
      data[, boundary := gsub("_.*", "", range)]
      data[, range := as.numeric(gsub("^.*?_","", range))]
    }

    data <- data.table::dcast(data, ... ~ boundary,
                              value.var = "predictions")
    res <- data[, "interval_score" := do.call(scoringutils::interval_score,
                                              c(list(true_values,
                                                     lower,
                                                     upper,
                                                     range),
                                                interval_score_arguments))]

    # compute calibration
    res[, calibration := mean(true_values >= lower & true_values <= upper),
        by = c("range", by)]

    # compute bias as fraction of true_values above the median and transformed to [-1, 1]
    # only possible if median forecast exists
    if (0 %in% unique(res$range)) {
      bias <- res[range == 0,
                  .(bias = 1 - 2 * mean(true_values > lower)),
                  by = by]

      res <-  merge(res, bias, by = by)
    }


    # compute sharpness as average width of the 50% interval
    if (50 %in% unique(res$range)) {
      sharpness <- res[range == 50, .(sharpness = mean(upper - lower)),
                       by = by]
      res <-  merge(res, sharpness, by = by)
    }

    if (summarised) {

      if (!is.null(quantiles)) {
        # add quantiles for the scores
        res <- add_quantiles(res,
                             c("interval_score", "calibration", "bias", "sharpness"),
                             quantiles,
                             by = c(summarise_by, "range"))
      }

      # add standard deviation
      if (sd) {
        res <- add_sd(res,
                      varnames = c("interval_score", "bias", "calibration", "sharpness"),
                      by = c(summarise_by, "range"))
      }

      # summarise by taking the mean and omitting unecessary columns
      res <- res[, lapply(.SD, mean, na.rm = TRUE),
                 by = c(summarise_by, "range"),
                 .SDcols = colnames(res) %like% "calibration|bias|sharpness|interval_score"]
    }
    return(res)
  }


  # Score integer or continuous predictions ------------------------------------
  # sharpness
  data[, sharpness := scoringutils::sharpness(t(predictions)), by = c("id", by)]

  # bias
  data[, bias := scoringutils::bias(unique(true_values),
                                     t(predictions)), by = c("id", by)]

  # DSS
  data[, dss := scoringutils::dss(unique(true_values),
                                    t(predictions)), by = c("id", by)]

  # CRPS
  data[, crps := scoringutils::crps(unique(true_values),
                                    t(predictions)), by = c("id", by)]

  # Log Score
  if (prediction_type == "continuous") {
    data[, log_score := scoringutils::logs(unique(true_values),
                                       t(predictions)), by = c("id", by)]
  }

  # calibration
  # reformat data.table to wide format
  dat <- data.table::dcast(data, ... ~ paste("sampl_", sample, sep = ""),
                           value.var = "predictions")

  # # code to get better names for the list elements
  # dt <- unique(dat[, colnames(dat) %in% by, with = FALSE])
  # do.call(paste, dt)

  # extract pit plots if specified
  if (pit_plots) {
    if (is.null(pit_arguments$plot) | !pit_arguments$plot) {
      pit_arguments$plot <- TRUE
    }
    split_dat <- split(dat, by = by)

    pits <- lapply(split_dat,
                   FUN = function(dat) {
                     samples <- as.matrix(dat[, grepl("sampl_", colnames(dat)),
                                              with = FALSE])

                     res <- do.call(pit, c(list(dat$true_values,
                                         samples),
                                    pit_arguments))

                     dat[, `:=` (pit_p_val = res$p_value,
                                 pit_sd = res$sd)]
                     plot <- res$hist_PIT
                     return(list(data = dat,
                                 hist_PIT = plot))
                   })

    pit_plots <- lapply(pits,
                        FUN = function(pit) {
                          return(pit$hist_PIT)
                        })

    pit_values <- lapply(pits,
                         FUN = function(pit) {
                           return(pit$data)
                         })

    dat <- rbindlist(pit_values, )
  } else {
    # compute pit p-values in a quicker way
    dat[, c("pit_p_val", "pit_sd") := do.call(pit, c(list(true_values,
                                                          as.matrix(.SD)),
                                                     pit_arguments)),
        .SDcols = names(dat)[grepl("sampl_", names(dat))], by = by]

  }

  # remove variables not necessary for merging
  dat[, names(dat)[grepl("sampl_", names(dat))] := NULL]
  dat[, c("sharpness", "bias", "dss", "crps") := NULL]

  # merge with previous data
  merge_cols = colnames(dat)[!colnames(dat) %in% c("pit_p_val", "pit_sd")]
  res <- merge(data, dat, by = merge_cols)

  # make scores unique to avoid redundancy.
  res <- res[, lapply(.SD, unique),
             .SDcols = colnames(res) %like% "pit_|bias|sharpness|dss|crps|log_score",
             by = c("id", by)]


  if (summarised) {
    # add quantiles
    if (!is.null(quantiles)) {

      if (prediction_type == "continuous") {
        quantile_vars <- c("crps", "dss", "log_score", "pit_p_val", "bias", "sharpness")
      } else {
        quantile_vars <- c("crps", "dss", "pit_p_val", "bias", "sharpness")
      }
      res <- add_quantiles(res, quantile_vars, quantiles, by = c(summarise_by))
    }

    if (sd) {
      # add standard deviations
      if (prediction_type == "continuous") {
        sd_vars <- c("crps", "dss", "log_score", "bias", "sharpness")
      } else {
        sd_vars <- c("crps", "dss", "bias", "sharpness")
      }

      res <- add_sd(res,
                    varnames = sd_vars,
                    by = c(summarise_by))
    }

    res <- res[, lapply(.SD, mean, na.rm = TRUE),
               .SDcols = colnames(res) %like% "pit_|bias|sharpness|dss|crps|log_score",
               by = summarise_by]
  }

  # if pit_plots is TRUE, add the plots as an output
  if (pit_plots) {
    res <- list(scores = res,
                pit_plots = pit_plots)
  }

  return (res)
}










